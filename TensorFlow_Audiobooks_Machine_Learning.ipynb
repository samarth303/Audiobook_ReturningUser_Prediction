{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the machine learning algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the train data in the temporary variable\n",
    "\n",
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "\n",
    "# we extract the inputs and targets using the keyword under which we saved them\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "# we load the validation data inputs and targets in the temporary variable\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "# we load the test data inputs and targets in the temporary variable\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Outline, optimizers, loss, early stopping and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3579 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "3579/3579 - 1s - loss: 0.5952 - accuracy: 0.8181 - val_loss: 0.5164 - val_accuracy: 0.8345\n",
      "Epoch 2/100\n",
      "3579/3579 - 0s - loss: 0.4180 - accuracy: 0.8793 - val_loss: 0.3778 - val_accuracy: 0.8523\n",
      "Epoch 3/100\n",
      "3579/3579 - 0s - loss: 0.3272 - accuracy: 0.8843 - val_loss: 0.3497 - val_accuracy: 0.8591\n",
      "Epoch 4/100\n",
      "3579/3579 - 0s - loss: 0.3038 - accuracy: 0.8863 - val_loss: 0.3399 - val_accuracy: 0.8658\n",
      "Epoch 5/100\n",
      "3579/3579 - 0s - loss: 0.2891 - accuracy: 0.8919 - val_loss: 0.3248 - val_accuracy: 0.8702\n",
      "Epoch 6/100\n",
      "3579/3579 - 0s - loss: 0.2787 - accuracy: 0.8941 - val_loss: 0.3226 - val_accuracy: 0.8702\n",
      "Epoch 7/100\n",
      "3579/3579 - 0s - loss: 0.2710 - accuracy: 0.8963 - val_loss: 0.3170 - val_accuracy: 0.8747\n",
      "Epoch 8/100\n",
      "3579/3579 - 0s - loss: 0.2669 - accuracy: 0.8989 - val_loss: 0.3177 - val_accuracy: 0.8770\n",
      "Epoch 9/100\n",
      "3579/3579 - 0s - loss: 0.2621 - accuracy: 0.8989 - val_loss: 0.3128 - val_accuracy: 0.8770\n",
      "Epoch 10/100\n",
      "3579/3579 - 0s - loss: 0.2578 - accuracy: 0.9016 - val_loss: 0.3151 - val_accuracy: 0.8792\n",
      "Epoch 11/100\n",
      "3579/3579 - 0s - loss: 0.2523 - accuracy: 0.9042 - val_loss: 0.3111 - val_accuracy: 0.8770\n",
      "Epoch 12/100\n",
      "3579/3579 - 0s - loss: 0.2493 - accuracy: 0.9056 - val_loss: 0.2960 - val_accuracy: 0.8837\n",
      "Epoch 13/100\n",
      "3579/3579 - 0s - loss: 0.2471 - accuracy: 0.9053 - val_loss: 0.3010 - val_accuracy: 0.8814\n",
      "Epoch 14/100\n",
      "3579/3579 - 0s - loss: 0.2435 - accuracy: 0.9084 - val_loss: 0.2930 - val_accuracy: 0.8859\n",
      "Epoch 15/100\n",
      "3579/3579 - 0s - loss: 0.2419 - accuracy: 0.9103 - val_loss: 0.2933 - val_accuracy: 0.8837\n",
      "Epoch 16/100\n",
      "3579/3579 - 0s - loss: 0.2404 - accuracy: 0.9106 - val_loss: 0.2877 - val_accuracy: 0.8859\n",
      "Epoch 17/100\n",
      "3579/3579 - 0s - loss: 0.2404 - accuracy: 0.9114 - val_loss: 0.2864 - val_accuracy: 0.8859\n",
      "Epoch 18/100\n",
      "3579/3579 - 0s - loss: 0.2413 - accuracy: 0.9120 - val_loss: 0.2872 - val_accuracy: 0.8904\n",
      "Epoch 19/100\n",
      "3579/3579 - 0s - loss: 0.2328 - accuracy: 0.9109 - val_loss: 0.2884 - val_accuracy: 0.8904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26d40745fc8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 70\n",
    "    \n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adamax', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "\n",
    "model.fit(train_inputs, \n",
    "          train_targets, \n",
    "          batch_size=batch_size,\n",
    "          epochs=max_epochs, \n",
    "          callbacks=[early_stopping], \n",
    "          validation_data=(validation_inputs, validation_targets), \n",
    "          verbose = 2 \n",
    "          )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "As we discussed in the lectures, after training on the training data and validating on the validation data, we test the final prediction power of our model by running it on the test dataset that the algorithm has NEVER seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 0s 205us/sample - loss: 0.2574 - accuracy: 0.9018\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.26. Test accuracy: 90.18%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(pred,columns=['Predicted'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['Actual'] = test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1\n",
       "Actual             \n",
       "0          201   24\n",
       "1           20  203"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(output['Actual'], output['Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "- It represents percentage of prediction our model got right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy: 90.18%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (confusion_matrix.loc[1,1]+confusion_matrix.loc[0,0])/(confusion_matrix.loc[1,1]+confusion_matrix.loc[0,1] + confusion_matrix.loc[1,0] + confusion_matrix.loc[0,0])\n",
    "print('\\n Accuracy: {0:.2f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "- It represents out of total predicted returning users how many percent of users actually returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Precision: 89.43%\n"
     ]
    }
   ],
   "source": [
    "precision = confusion_matrix.loc[1,1]/(confusion_matrix.loc[1,1]+confusion_matrix.loc[0,1])\n",
    "print('\\n Precision: {0:.2f}%'.format(precision*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "- It represents out of total returning users how many we predicted. It is also names as hit ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Recall: 89.43%\n"
     ]
    }
   ],
   "source": [
    "recall = confusion_matrix.loc[1,1]/(confusion_matrix.loc[1,1]+confusion_matrix.loc[1,0])\n",
    "print('\\n Recall: {0:.2f}%'.format(precision*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
